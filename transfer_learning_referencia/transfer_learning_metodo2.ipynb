{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZES = [100, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reads all images in filepath, resizes it according with 2D list img_sizes and \n",
    "# store them in a np_array. The string filepath can only contain images (no other\n",
    "# file types such as txt for example are allowed). \n",
    "# It works only for RGB images.\n",
    "def images_to_np_array(filepath, img_sizes):\n",
    "    #-----------------------------------------------------------------------------\n",
    "    # Args:\n",
    "    #     filepath:  String with the path to the directory containing the images.\n",
    "    #                It CANNOT end with the / character.\n",
    "    #     img_sizes: 2D array [num_rows, num_columns].\n",
    "    #-----------------------------------------------------------------------------\n",
    "\n",
    "    # list all files in filepath\n",
    "    list_of_files = [file for file in os.listdir(filepath)]\n",
    "\n",
    "    # number of image files\n",
    "    n_images = len(list_of_files)\n",
    "\n",
    "    # create np_array to store all images\n",
    "    array_images = np.zeros([n_images, IMAGE_SIZES[0], IMAGE_SIZES[1], 3])\n",
    "\n",
    "    for index in range( n_images ):\n",
    "\n",
    "        # get file name   \n",
    "        file_name = list_of_files[index]\n",
    "\n",
    "        # Open the image form working directory\n",
    "        image = Image.open(filepath + '/' + file_name)\n",
    "\n",
    "        # resize image\n",
    "        image_resized = image.resize(IMAGE_SIZES)\n",
    "\n",
    "        # convert it to numpy\n",
    "        np_image = np.asarray(image_resized)\n",
    "        array_images[index,:,:,:] = np_image\n",
    "\n",
    "    return array_images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building training data\n",
    "\n",
    "# read all capivaras\n",
    "capivara_train = images_to_np_array(filepath = \"./capivara_augmented\", img_sizes = IMAGE_SIZES)\n",
    "y_capivara_train = np.zeros(capivara_train.shape[0])\n",
    "\n",
    "# read all dunkies\n",
    "burro_train = images_to_np_array(filepath = \"./burro_augmented\", img_sizes = IMAGE_SIZES)\n",
    "y_burro_train = np.ones(burro_train.shape[0])\n",
    "\n",
    "# create y vector with labels\n",
    "y_train = np.concatenate( (y_capivara_train, y_burro_train) )\n",
    "\n",
    "# concatenate and shuffle images\n",
    "array_train = np.concatenate( (capivara_train, burro_train), axis = 0 )\n",
    "number_of_images = array_train.shape[0]\n",
    "permuted_index = np.random.permutation(number_of_images)\n",
    "\n",
    "# training data\n",
    "x_train = array_train[permuted_index, :, :, :]\n",
    "y_train = y_train[permuted_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building test data\n",
    "\n",
    "# read all capivaras\n",
    "capivara_test = images_to_np_array(filepath = \"./capivara_test\", img_sizes = IMAGE_SIZES)\n",
    "y_capivara_test = np.zeros(capivara_test.shape[0])\n",
    "\n",
    "# read all dunkies\n",
    "burro_test = images_to_np_array(filepath = \"./burro_test\", img_sizes = IMAGE_SIZES)\n",
    "y_burro_test = np.ones(burro_test.shape[0])\n",
    "\n",
    "# create y vector with labels\n",
    "y_test = np.concatenate( (y_capivara_test, y_burro_test) )\n",
    "\n",
    "# concatenate and shuffle images\n",
    "array_test = np.concatenate( (capivara_test, burro_test), axis = 0 )\n",
    "number_of_images = array_test.shape[0]\n",
    "permuted_index = np.random.permutation(number_of_images)\n",
    "\n",
    "# test data\n",
    "x_test = array_test[permuted_index, :, :, :]\n",
    "y_test = y_test[permuted_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing \n",
    "x_train = tf.keras.applications.densenet.preprocess_input(x_train, data_format = \"channels_last\")\n",
    "x_test = tf.keras.applications.densenet.preprocess_input(x_test, data_format = \"channels_last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-15 21:03:28.742230: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-15 21:03:28.838589: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-15 21:03:28.838797: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-15 21:03:28.840026: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-15 21:03:28.840833: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-15 21:03:28.841092: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-15 21:03:28.841249: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-15 21:03:29.765496: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-15 21:03:29.765709: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-15 21:03:29.765925: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-15 21:03:29.766166: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2633 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# initialize model with weights treined in imagenet \n",
    "base_model = tf.keras.applications.DenseNet169(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(IMAGE_SIZES[0], IMAGE_SIZES[1], 3),\n",
    "    pooling=\"avg\",\n",
    "    classes=2,\n",
    "    classifier_activation=\"None\"\n",
    ")\n",
    "\n",
    "# Freeze model weights\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 100, 100, 3)]     0         \n",
      "                                                                 \n",
      " densenet169 (Functional)    (None, 1664)              12642880  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1664)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               166500    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,829,681\n",
      "Trainable params: 186,801\n",
      "Non-trainable params: 12,642,880\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(IMAGE_SIZES[0], IMAGE_SIZES[1], 3))\n",
    "# We make sure that the base_model is running in inference mode here,\n",
    "# by passing `training=False`. This is important for fine-tuning\n",
    "x = base_model(inputs, training=False)\n",
    "# Convert features of shape `base_model.output_shape[1:]` to vectors\n",
    "x = tf.keras.layers.Flatten(data_format = \"channels_last\")(x)\n",
    "x = tf.keras.layers.Dense(100, activation = \"relu\")(x)\n",
    "x = tf.keras.layers.Dense(100, activation = \"relu\")(x)\n",
    "x = tf.keras.layers.Dense(100, activation = \"relu\")(x)\n",
    "outputs = tf.keras.layers.Dense(1)(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-15 21:03:34.444987: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 360120000 exceeds 10% of free system memory.\n",
      "2022-08-15 21:03:34.783093: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 360120000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-15 21:03:44.511720: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8401\n",
      "2022-08-15 21:03:45.921066: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 [==============================] - 24s 163ms/step - loss: 0.5667 - binary_accuracy: 0.7338 - val_loss: 0.5879 - val_binary_accuracy: 0.5500\n",
      "Epoch 2/100\n",
      "61/61 [==============================] - 6s 95ms/step - loss: 0.4486 - binary_accuracy: 0.7534 - val_loss: 0.5096 - val_binary_accuracy: 0.5950\n",
      "Epoch 3/100\n",
      "61/61 [==============================] - 6s 95ms/step - loss: 0.3780 - binary_accuracy: 0.8044 - val_loss: 0.4350 - val_binary_accuracy: 0.6750\n",
      "Epoch 4/100\n",
      "61/61 [==============================] - 6s 95ms/step - loss: 0.3220 - binary_accuracy: 0.8407 - val_loss: 0.3691 - val_binary_accuracy: 0.7250\n",
      "Epoch 5/100\n",
      "61/61 [==============================] - 6s 95ms/step - loss: 0.2795 - binary_accuracy: 0.8747 - val_loss: 0.3140 - val_binary_accuracy: 0.8050\n",
      "Epoch 6/100\n",
      "61/61 [==============================] - 6s 95ms/step - loss: 0.2469 - binary_accuracy: 0.9000 - val_loss: 0.2821 - val_binary_accuracy: 0.8150\n",
      "Epoch 7/100\n",
      "61/61 [==============================] - 6s 96ms/step - loss: 0.2235 - binary_accuracy: 0.9117 - val_loss: 0.2557 - val_binary_accuracy: 0.8350\n",
      "Epoch 8/100\n",
      "61/61 [==============================] - 6s 95ms/step - loss: 0.2056 - binary_accuracy: 0.9207 - val_loss: 0.2371 - val_binary_accuracy: 0.8600\n",
      "Epoch 9/100\n",
      "61/61 [==============================] - 6s 95ms/step - loss: 0.1908 - binary_accuracy: 0.9224 - val_loss: 0.2291 - val_binary_accuracy: 0.8650\n",
      "Epoch 10/100\n",
      "61/61 [==============================] - 6s 95ms/step - loss: 0.1787 - binary_accuracy: 0.9267 - val_loss: 0.2119 - val_binary_accuracy: 0.8800\n",
      "Epoch 11/100\n",
      "61/61 [==============================] - 6s 96ms/step - loss: 0.1682 - binary_accuracy: 0.9334 - val_loss: 0.1999 - val_binary_accuracy: 0.8950\n",
      "Epoch 12/100\n",
      "61/61 [==============================] - 6s 96ms/step - loss: 0.1589 - binary_accuracy: 0.9354 - val_loss: 0.1902 - val_binary_accuracy: 0.8950\n",
      "Epoch 13/100\n",
      "61/61 [==============================] - 6s 96ms/step - loss: 0.1507 - binary_accuracy: 0.9417 - val_loss: 0.1836 - val_binary_accuracy: 0.8900\n",
      "Epoch 14/100\n",
      "61/61 [==============================] - 6s 96ms/step - loss: 0.1433 - binary_accuracy: 0.9430 - val_loss: 0.1749 - val_binary_accuracy: 0.9050\n",
      "Epoch 15/100\n",
      "61/61 [==============================] - 6s 95ms/step - loss: 0.1371 - binary_accuracy: 0.9500 - val_loss: 0.1730 - val_binary_accuracy: 0.9050\n",
      "Epoch 16/100\n",
      "61/61 [==============================] - 6s 96ms/step - loss: 0.1312 - binary_accuracy: 0.9513 - val_loss: 0.1666 - val_binary_accuracy: 0.9100\n",
      "Epoch 17/100\n",
      "61/61 [==============================] - 6s 95ms/step - loss: 0.1259 - binary_accuracy: 0.9540 - val_loss: 0.1697 - val_binary_accuracy: 0.9150\n",
      "Epoch 18/100\n",
      "61/61 [==============================] - 6s 96ms/step - loss: 0.1209 - binary_accuracy: 0.9520 - val_loss: 0.1553 - val_binary_accuracy: 0.9250\n",
      "Epoch 19/100\n",
      "61/61 [==============================] - 6s 96ms/step - loss: 0.1162 - binary_accuracy: 0.9577 - val_loss: 0.1551 - val_binary_accuracy: 0.9250\n",
      "Epoch 20/100\n",
      "61/61 [==============================] - 6s 96ms/step - loss: 0.1118 - binary_accuracy: 0.9597 - val_loss: 0.1577 - val_binary_accuracy: 0.9250\n",
      "Epoch 21/100\n",
      "61/61 [==============================] - 6s 95ms/step - loss: 0.1076 - binary_accuracy: 0.9617 - val_loss: 0.1560 - val_binary_accuracy: 0.9300\n",
      "Epoch 22/100\n",
      "61/61 [==============================] - 6s 96ms/step - loss: 0.1038 - binary_accuracy: 0.9640 - val_loss: 0.1518 - val_binary_accuracy: 0.9250\n",
      "Epoch 23/100\n",
      "61/61 [==============================] - 6s 96ms/step - loss: 0.0998 - binary_accuracy: 0.9663 - val_loss: 0.1518 - val_binary_accuracy: 0.9250\n",
      "Epoch 24/100\n",
      "61/61 [==============================] - 6s 96ms/step - loss: 0.0964 - binary_accuracy: 0.9663 - val_loss: 0.1476 - val_binary_accuracy: 0.9450\n",
      "Epoch 25/100\n",
      "61/61 [==============================] - 6s 96ms/step - loss: 0.0930 - binary_accuracy: 0.9693 - val_loss: 0.1504 - val_binary_accuracy: 0.9400\n",
      "Epoch 26/100\n",
      "61/61 [==============================] - 6s 96ms/step - loss: 0.0897 - binary_accuracy: 0.9680 - val_loss: 0.1444 - val_binary_accuracy: 0.9450\n",
      "Epoch 27/100\n",
      "61/61 [==============================] - 6s 96ms/step - loss: 0.0865 - binary_accuracy: 0.9720 - val_loss: 0.1512 - val_binary_accuracy: 0.9400\n",
      "Epoch 28/100\n",
      "61/61 [==============================] - 6s 96ms/step - loss: 0.0839 - binary_accuracy: 0.9710 - val_loss: 0.1472 - val_binary_accuracy: 0.9500\n",
      "Epoch 29/100\n",
      "61/61 [==============================] - 6s 96ms/step - loss: 0.0811 - binary_accuracy: 0.9733 - val_loss: 0.1537 - val_binary_accuracy: 0.9400\n",
      "Epoch 30/100\n",
      "61/61 [==============================] - 6s 95ms/step - loss: 0.0785 - binary_accuracy: 0.9737 - val_loss: 0.1489 - val_binary_accuracy: 0.9450\n",
      "Epoch 31/100\n",
      "61/61 [==============================] - 6s 96ms/step - loss: 0.0759 - binary_accuracy: 0.9747 - val_loss: 0.1471 - val_binary_accuracy: 0.9450\n",
      "Epoch 32/100\n",
      "61/61 [==============================] - 6s 96ms/step - loss: 0.0735 - binary_accuracy: 0.9763 - val_loss: 0.1467 - val_binary_accuracy: 0.9500\n",
      "Epoch 33/100\n",
      "61/61 [==============================] - 6s 96ms/step - loss: 0.0713 - binary_accuracy: 0.9770 - val_loss: 0.1501 - val_binary_accuracy: 0.9450\n",
      "Epoch 34/100\n",
      "61/61 [==============================] - 6s 96ms/step - loss: 0.0690 - binary_accuracy: 0.9770 - val_loss: 0.1481 - val_binary_accuracy: 0.9450\n",
      "Epoch 35/100\n",
      "61/61 [==============================] - 6s 96ms/step - loss: 0.0667 - binary_accuracy: 0.9777 - val_loss: 0.1521 - val_binary_accuracy: 0.9500\n",
      "Epoch 36/100\n",
      "61/61 [==============================] - 6s 96ms/step - loss: 0.0646 - binary_accuracy: 0.9787 - val_loss: 0.1466 - val_binary_accuracy: 0.9550\n",
      "Epoch 37/100\n",
      "61/61 [==============================] - 6s 96ms/step - loss: 0.0626 - binary_accuracy: 0.9817 - val_loss: 0.1535 - val_binary_accuracy: 0.9450\n",
      "Epoch 38/100\n",
      "61/61 [==============================] - 6s 96ms/step - loss: 0.0611 - binary_accuracy: 0.9820 - val_loss: 0.1548 - val_binary_accuracy: 0.9450\n",
      "Epoch 39/100\n",
      "61/61 [==============================] - 6s 96ms/step - loss: 0.0586 - binary_accuracy: 0.9830 - val_loss: 0.1565 - val_binary_accuracy: 0.9450\n",
      "Epoch 40/100\n",
      "61/61 [==============================] - 6s 96ms/step - loss: 0.0569 - binary_accuracy: 0.9837 - val_loss: 0.1548 - val_binary_accuracy: 0.9500\n",
      "Epoch 41/100\n",
      "61/61 [==============================] - 6s 96ms/step - loss: 0.0548 - binary_accuracy: 0.9850 - val_loss: 0.1517 - val_binary_accuracy: 0.9550\n",
      "Epoch 42/100\n",
      "61/61 [==============================] - 6s 96ms/step - loss: 0.0531 - binary_accuracy: 0.9850 - val_loss: 0.1534 - val_binary_accuracy: 0.9550\n",
      "Epoch 43/100\n",
      "61/61 [==============================] - 6s 96ms/step - loss: 0.0513 - binary_accuracy: 0.9860 - val_loss: 0.1545 - val_binary_accuracy: 0.9500\n",
      "Epoch 44/100\n",
      "61/61 [==============================] - 6s 95ms/step - loss: 0.0498 - binary_accuracy: 0.9860 - val_loss: 0.1603 - val_binary_accuracy: 0.9500\n",
      "Epoch 45/100\n",
      "61/61 [==============================] - 6s 96ms/step - loss: 0.0480 - binary_accuracy: 0.9873 - val_loss: 0.1592 - val_binary_accuracy: 0.9500\n",
      "Epoch 46/100\n",
      "61/61 [==============================] - 6s 96ms/step - loss: 0.0463 - binary_accuracy: 0.9873 - val_loss: 0.1609 - val_binary_accuracy: 0.9500\n",
      "Epoch 47/100\n",
      "61/61 [==============================] - 6s 97ms/step - loss: 0.0447 - binary_accuracy: 0.9877 - val_loss: 0.1607 - val_binary_accuracy: 0.9500\n",
      "Epoch 48/100\n",
      "61/61 [==============================] - 6s 96ms/step - loss: 0.0431 - binary_accuracy: 0.9880 - val_loss: 0.1611 - val_binary_accuracy: 0.9500\n",
      "Epoch 49/100\n",
      "61/61 [==============================] - 6s 96ms/step - loss: 0.0416 - binary_accuracy: 0.9887 - val_loss: 0.1632 - val_binary_accuracy: 0.9500\n",
      "Epoch 50/100\n",
      "61/61 [==============================] - 6s 96ms/step - loss: 0.0403 - binary_accuracy: 0.9880 - val_loss: 0.1629 - val_binary_accuracy: 0.9500\n",
      "Epoch 51/100\n",
      "61/61 [==============================] - 6s 96ms/step - loss: 0.0385 - binary_accuracy: 0.9887 - val_loss: 0.1588 - val_binary_accuracy: 0.9550\n",
      "Epoch 52/100\n",
      "61/61 [==============================] - 6s 96ms/step - loss: 0.0372 - binary_accuracy: 0.9903 - val_loss: 0.1628 - val_binary_accuracy: 0.9500\n",
      "Epoch 53/100\n",
      "61/61 [==============================] - 6s 97ms/step - loss: 0.0358 - binary_accuracy: 0.9917 - val_loss: 0.1660 - val_binary_accuracy: 0.9500\n",
      "Epoch 54/100\n",
      "61/61 [==============================] - 6s 96ms/step - loss: 0.0344 - binary_accuracy: 0.9917 - val_loss: 0.1682 - val_binary_accuracy: 0.9500\n",
      "Epoch 55/100\n",
      "61/61 [==============================] - 37s 614ms/step - loss: 0.0334 - binary_accuracy: 0.9913 - val_loss: 0.1672 - val_binary_accuracy: 0.9500\n",
      "Epoch 56/100\n",
      "61/61 [==============================] - 47s 775ms/step - loss: 0.0319 - binary_accuracy: 0.9920 - val_loss: 0.1625 - val_binary_accuracy: 0.9500\n",
      "Epoch 57/100\n",
      "61/61 [==============================] - 47s 774ms/step - loss: 0.0325 - binary_accuracy: 0.9937 - val_loss: 0.1703 - val_binary_accuracy: 0.9500\n",
      "Epoch 58/100\n",
      "61/61 [==============================] - 19s 308ms/step - loss: 0.0301 - binary_accuracy: 0.9937 - val_loss: 0.1701 - val_binary_accuracy: 0.9500\n",
      "Epoch 59/100\n",
      "61/61 [==============================] - 5s 79ms/step - loss: 0.0289 - binary_accuracy: 0.9930 - val_loss: 0.1643 - val_binary_accuracy: 0.9500\n",
      "Epoch 60/100\n",
      "61/61 [==============================] - 5s 79ms/step - loss: 0.0279 - binary_accuracy: 0.9940 - val_loss: 0.1693 - val_binary_accuracy: 0.9550\n",
      "Epoch 61/100\n",
      "61/61 [==============================] - 5s 79ms/step - loss: 0.0268 - binary_accuracy: 0.9947 - val_loss: 0.1691 - val_binary_accuracy: 0.9550\n",
      "Epoch 62/100\n",
      "61/61 [==============================] - 5s 79ms/step - loss: 0.0259 - binary_accuracy: 0.9953 - val_loss: 0.1753 - val_binary_accuracy: 0.9550\n",
      "Epoch 63/100\n",
      "61/61 [==============================] - 5s 79ms/step - loss: 0.0249 - binary_accuracy: 0.9950 - val_loss: 0.1710 - val_binary_accuracy: 0.9550\n",
      "Epoch 64/100\n",
      "61/61 [==============================] - 5s 78ms/step - loss: 0.0240 - binary_accuracy: 0.9960 - val_loss: 0.1778 - val_binary_accuracy: 0.9550\n",
      "Epoch 65/100\n",
      "61/61 [==============================] - 5s 79ms/step - loss: 0.0231 - binary_accuracy: 0.9957 - val_loss: 0.1729 - val_binary_accuracy: 0.9550\n",
      "Epoch 66/100\n",
      "61/61 [==============================] - 5s 79ms/step - loss: 0.0224 - binary_accuracy: 0.9963 - val_loss: 0.1804 - val_binary_accuracy: 0.9550\n",
      "Epoch 67/100\n",
      "61/61 [==============================] - 5s 79ms/step - loss: 0.0216 - binary_accuracy: 0.9967 - val_loss: 0.1767 - val_binary_accuracy: 0.9550\n",
      "Epoch 68/100\n",
      "61/61 [==============================] - 5s 80ms/step - loss: 0.0208 - binary_accuracy: 0.9973 - val_loss: 0.1769 - val_binary_accuracy: 0.9500\n",
      "Epoch 69/100\n",
      "61/61 [==============================] - 5s 79ms/step - loss: 0.0201 - binary_accuracy: 0.9973 - val_loss: 0.1810 - val_binary_accuracy: 0.9550\n",
      "Epoch 70/100\n",
      "61/61 [==============================] - 5s 80ms/step - loss: 0.0193 - binary_accuracy: 0.9977 - val_loss: 0.1832 - val_binary_accuracy: 0.9550\n",
      "Epoch 71/100\n",
      "61/61 [==============================] - 5s 79ms/step - loss: 0.0186 - binary_accuracy: 0.9977 - val_loss: 0.1905 - val_binary_accuracy: 0.9550\n",
      "Epoch 72/100\n",
      "61/61 [==============================] - 5s 79ms/step - loss: 0.0179 - binary_accuracy: 0.9983 - val_loss: 0.1834 - val_binary_accuracy: 0.9550\n",
      "Epoch 73/100\n",
      "61/61 [==============================] - 5s 79ms/step - loss: 0.0172 - binary_accuracy: 0.9990 - val_loss: 0.1858 - val_binary_accuracy: 0.9550\n",
      "Epoch 74/100\n",
      "61/61 [==============================] - 5s 79ms/step - loss: 0.0165 - binary_accuracy: 0.9983 - val_loss: 0.1851 - val_binary_accuracy: 0.9500\n",
      "Epoch 75/100\n",
      "61/61 [==============================] - 5s 79ms/step - loss: 0.0160 - binary_accuracy: 0.9997 - val_loss: 0.1887 - val_binary_accuracy: 0.9500\n",
      "Epoch 76/100\n",
      "61/61 [==============================] - 5s 79ms/step - loss: 0.0152 - binary_accuracy: 0.9993 - val_loss: 0.1874 - val_binary_accuracy: 0.9500\n",
      "Epoch 77/100\n",
      "61/61 [==============================] - 5s 79ms/step - loss: 0.0147 - binary_accuracy: 0.9997 - val_loss: 0.1908 - val_binary_accuracy: 0.9500\n",
      "Epoch 78/100\n",
      "61/61 [==============================] - 5s 80ms/step - loss: 0.0141 - binary_accuracy: 0.9997 - val_loss: 0.1894 - val_binary_accuracy: 0.9500\n",
      "Epoch 79/100\n",
      "61/61 [==============================] - 5s 79ms/step - loss: 0.0135 - binary_accuracy: 0.9997 - val_loss: 0.1930 - val_binary_accuracy: 0.9500\n",
      "Epoch 80/100\n",
      "61/61 [==============================] - 5s 79ms/step - loss: 0.0131 - binary_accuracy: 0.9997 - val_loss: 0.1919 - val_binary_accuracy: 0.9500\n",
      "Epoch 81/100\n",
      "61/61 [==============================] - 5s 79ms/step - loss: 0.0126 - binary_accuracy: 0.9997 - val_loss: 0.1970 - val_binary_accuracy: 0.9500\n",
      "Epoch 82/100\n",
      "61/61 [==============================] - 5s 80ms/step - loss: 0.0121 - binary_accuracy: 0.9997 - val_loss: 0.1970 - val_binary_accuracy: 0.9500\n",
      "Epoch 83/100\n",
      "61/61 [==============================] - 5s 79ms/step - loss: 0.0116 - binary_accuracy: 0.9997 - val_loss: 0.2006 - val_binary_accuracy: 0.9500\n",
      "Epoch 84/100\n",
      "61/61 [==============================] - 5s 79ms/step - loss: 0.0111 - binary_accuracy: 0.9997 - val_loss: 0.2010 - val_binary_accuracy: 0.9500\n",
      "Epoch 85/100\n",
      "61/61 [==============================] - 5s 78ms/step - loss: 0.0107 - binary_accuracy: 0.9997 - val_loss: 0.2030 - val_binary_accuracy: 0.9500\n",
      "Epoch 86/100\n",
      "61/61 [==============================] - 5s 79ms/step - loss: 0.0103 - binary_accuracy: 0.9997 - val_loss: 0.2003 - val_binary_accuracy: 0.9500\n",
      "Epoch 87/100\n",
      "61/61 [==============================] - 5s 79ms/step - loss: 0.0099 - binary_accuracy: 0.9997 - val_loss: 0.2075 - val_binary_accuracy: 0.9500\n",
      "Epoch 88/100\n",
      "61/61 [==============================] - 5s 78ms/step - loss: 0.0094 - binary_accuracy: 1.0000 - val_loss: 0.2033 - val_binary_accuracy: 0.9500\n",
      "Epoch 89/100\n",
      "61/61 [==============================] - 5s 80ms/step - loss: 0.0091 - binary_accuracy: 1.0000 - val_loss: 0.2024 - val_binary_accuracy: 0.9500\n",
      "Epoch 90/100\n",
      "61/61 [==============================] - 5s 79ms/step - loss: 0.0088 - binary_accuracy: 1.0000 - val_loss: 0.2053 - val_binary_accuracy: 0.9500\n",
      "Epoch 91/100\n",
      "61/61 [==============================] - 5s 79ms/step - loss: 0.0085 - binary_accuracy: 1.0000 - val_loss: 0.2059 - val_binary_accuracy: 0.9500\n",
      "Epoch 92/100\n",
      "61/61 [==============================] - 5s 80ms/step - loss: 0.0084 - binary_accuracy: 1.0000 - val_loss: 0.2150 - val_binary_accuracy: 0.9500\n",
      "Epoch 93/100\n",
      "61/61 [==============================] - 5s 80ms/step - loss: 0.0078 - binary_accuracy: 1.0000 - val_loss: 0.2125 - val_binary_accuracy: 0.9500\n",
      "Epoch 94/100\n",
      "61/61 [==============================] - 5s 80ms/step - loss: 0.0075 - binary_accuracy: 1.0000 - val_loss: 0.2181 - val_binary_accuracy: 0.9450\n",
      "Epoch 95/100\n",
      "61/61 [==============================] - 5s 80ms/step - loss: 0.0072 - binary_accuracy: 1.0000 - val_loss: 0.2188 - val_binary_accuracy: 0.9450\n",
      "Epoch 96/100\n",
      "61/61 [==============================] - 5s 80ms/step - loss: 0.0069 - binary_accuracy: 1.0000 - val_loss: 0.2179 - val_binary_accuracy: 0.9500\n",
      "Epoch 97/100\n",
      "61/61 [==============================] - 5s 79ms/step - loss: 0.0067 - binary_accuracy: 1.0000 - val_loss: 0.2186 - val_binary_accuracy: 0.9500\n",
      "Epoch 98/100\n",
      "61/61 [==============================] - 5s 79ms/step - loss: 0.0064 - binary_accuracy: 1.0000 - val_loss: 0.2202 - val_binary_accuracy: 0.9500\n",
      "Epoch 99/100\n",
      "61/61 [==============================] - 5s 80ms/step - loss: 0.0062 - binary_accuracy: 1.0000 - val_loss: 0.2180 - val_binary_accuracy: 0.9500\n",
      "Epoch 100/100\n",
      "61/61 [==============================] - 5s 80ms/step - loss: 0.0059 - binary_accuracy: 1.0000 - val_loss: 0.2241 - val_binary_accuracy: 0.9500\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate = 0.00001),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy()],\n",
    ")\n",
    "\n",
    "history = model.fit(x = x_train, \n",
    "                    y = y_train, \n",
    "                    epochs = 100, \n",
    "                    validation_data = (x_test, y_test), \n",
    "                    batch_size = 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 - 10s - loss: 0.2241 - binary_accuracy: 0.9500 - 10s/epoch - 1s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.22406305372714996, 0.949999988079071]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(y = y_test, x = x_test, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 2s 50ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>probability</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.757370e-01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.999642e-01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.999598e-01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.326939e-10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.340865e-08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>1.418207e-05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>9.998529e-01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>8.371415e-01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>7.265848e-05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>9.975188e-01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      probability  label\n",
       "0    9.757370e-01    1.0\n",
       "1    9.999642e-01    1.0\n",
       "2    9.999598e-01    1.0\n",
       "3    9.326939e-10    0.0\n",
       "4    3.340865e-08    0.0\n",
       "..            ...    ...\n",
       "195  1.418207e-05    0.0\n",
       "196  9.998529e-01    1.0\n",
       "197  8.371415e-01    0.0\n",
       "198  7.265848e-05    0.0\n",
       "199  9.975188e-01    1.0\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(x_test)\n",
    "pd.DataFrame( {\"probability\": tf.keras.activations.sigmoid(predictions)[:,0], \"label\": y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.566696286201477, 0.44864732027053833, 0.3780483305454254, 0.3220219612121582, 0.27948591113090515, 0.2469456046819687, 0.22345088422298431, 0.20557209849357605, 0.19076335430145264, 0.17874577641487122, 0.16819292306900024, 0.15892700850963593, 0.15073361992835999, 0.14333325624465942, 0.13707873225212097, 0.13119007647037506, 0.12592440843582153, 0.12089882045984268, 0.1161615252494812, 0.11175152659416199, 0.10764262825250626, 0.10376201570034027, 0.09976182132959366, 0.0963926836848259, 0.09300034493207932, 0.08970178663730621, 0.08645208925008774, 0.08389922231435776, 0.08111496269702911, 0.07850600779056549, 0.07587435841560364, 0.07348446547985077, 0.07129169255495071, 0.0689597949385643, 0.0666843056678772, 0.06457875669002533, 0.06263202428817749, 0.06111811473965645, 0.05862550437450409, 0.05688391998410225, 0.05482010170817375, 0.05308714881539345, 0.05129843205213547, 0.04975941404700279, 0.04797155410051346, 0.04633225128054619, 0.044715516269207, 0.04312175139784813, 0.04156709089875221, 0.04025391489267349, 0.03847607225179672, 0.03721778094768524, 0.035769686102867126, 0.03438865393400192, 0.03341342881321907, 0.0319153368473053, 0.032463934272527695, 0.0300904493778944, 0.028917502611875534, 0.027921387925744057, 0.026752183213829994, 0.025927649810910225, 0.024890121072530746, 0.023977719247341156, 0.023110931739211082, 0.022383805364370346, 0.021586714312434196, 0.020809147506952286, 0.02006927691400051, 0.01927817054092884, 0.018581578508019447, 0.017863864079117775, 0.017154086381196976, 0.016475103795528412, 0.015991101041436195, 0.015248330309987068, 0.014703313820064068, 0.014117574319243431, 0.01354130543768406, 0.013051205314695835, 0.012630525976419449, 0.012083958834409714, 0.01155739277601242, 0.011134694330394268, 0.01069160271435976, 0.01027092058211565, 0.009923978708684444, 0.009441670961678028, 0.009142979048192501, 0.008841722272336483, 0.008451307192444801, 0.008386051282286644, 0.007823368534445763, 0.0074867671355605125, 0.007231518626213074, 0.0069292280822992325, 0.006654838565737009, 0.006447536870837212, 0.006196870934218168, 0.005926170386373997], 'binary_accuracy': [0.7337554097175598, 0.7534155249595642, 0.8043985366821289, 0.8407197594642639, 0.8747084140777588, 0.9000332951545715, 0.9116960763931274, 0.9206930994987488, 0.9223592281341553, 0.9266911149024963, 0.9333555698394775, 0.9353548884391785, 0.9416860938072205, 0.9430189728736877, 0.9500166773796082, 0.9513495564460754, 0.95401531457901, 0.9520159959793091, 0.9576807618141174, 0.9596800804138184, 0.9616794586181641, 0.9640119671821594, 0.9663445353507996, 0.9663445353507996, 0.9693435430526733, 0.968010663986206, 0.9720093011856079, 0.9710096716880798, 0.97334223985672, 0.9736754298210144, 0.9746751189231873, 0.9763412475585938, 0.9770076870918274, 0.9770076870918274, 0.977674126625061, 0.9786737561225891, 0.9816727638244629, 0.9820060133934021, 0.9830056428909302, 0.9836720824241638, 0.9850050210952759, 0.9850050210952759, 0.986004650592804, 0.986004650592804, 0.9873375296592712, 0.9873375296592712, 0.9876707792282104, 0.9880039691925049, 0.9886704683303833, 0.9880039691925049, 0.9886704683303833, 0.990336537361145, 0.9916694164276123, 0.9916694164276123, 0.9913362264633179, 0.9920026659965515, 0.993668794631958, 0.993668794631958, 0.9930023550987244, 0.9940019845962524, 0.9946684241294861, 0.9953348636627197, 0.9950016736984253, 0.9960013031959534, 0.9956681132316589, 0.9963345527648926, 0.9966678023338318, 0.9973342418670654, 0.9973342418670654, 0.9976674318313599, 0.9976674318313599, 0.9983338713645935, 0.9990003108978271, 0.9983338713645935, 0.9996667504310608, 0.9993335604667664, 0.9996667504310608, 0.9996667504310608, 0.9996667504310608, 0.9996667504310608, 0.9996667504310608, 0.9996667504310608, 0.9996667504310608, 0.9996667504310608, 0.9996667504310608, 0.9996667504310608, 0.9996667504310608, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [0.587887704372406, 0.5096088647842407, 0.4350144565105438, 0.3691461980342865, 0.31401875615119934, 0.28208330273628235, 0.2556711435317993, 0.23708534240722656, 0.229095458984375, 0.211878702044487, 0.19992642104625702, 0.1902168244123459, 0.18356968462467194, 0.17485398054122925, 0.17298346757888794, 0.1666482388973236, 0.1697278618812561, 0.1552702784538269, 0.15509819984436035, 0.1576584279537201, 0.15600182116031647, 0.15176905691623688, 0.15184485912322998, 0.14761848747730255, 0.15039291977882385, 0.144434854388237, 0.15115408599376678, 0.14724522829055786, 0.15374529361724854, 0.14893943071365356, 0.14712771773338318, 0.14671336114406586, 0.15008282661437988, 0.1480921357870102, 0.15211331844329834, 0.14658719301223755, 0.15345002710819244, 0.15483146905899048, 0.15651461482048035, 0.1548316329717636, 0.15171173214912415, 0.1533593386411667, 0.15452812612056732, 0.16026313602924347, 0.15924085676670074, 0.16091272234916687, 0.16071540117263794, 0.1610720455646515, 0.16324558854103088, 0.1628676950931549, 0.15875451266765594, 0.16278164088726044, 0.16598165035247803, 0.16820165514945984, 0.1671539843082428, 0.1625293791294098, 0.17025363445281982, 0.17006520926952362, 0.1643209010362625, 0.16931027173995972, 0.1691419631242752, 0.1752772331237793, 0.1709517240524292, 0.17777332663536072, 0.17292045056819916, 0.18041889369487762, 0.17670482397079468, 0.1769130676984787, 0.18097491562366486, 0.18317072093486786, 0.19048328697681427, 0.18343815207481384, 0.1857987940311432, 0.18510940670967102, 0.18874263763427734, 0.187444269657135, 0.1908111572265625, 0.18939334154129028, 0.19299888610839844, 0.19191467761993408, 0.1969887614250183, 0.19704857468605042, 0.20059926807880402, 0.20100218057632446, 0.2029581218957901, 0.20027047395706177, 0.20754119753837585, 0.2032984495162964, 0.20238250494003296, 0.2053469717502594, 0.20589889585971832, 0.21496734023094177, 0.2125214785337448, 0.21811914443969727, 0.21882255375385284, 0.21788150072097778, 0.2185675948858261, 0.22018863260746002, 0.21803168952465057, 0.22406291961669922], 'val_binary_accuracy': [0.550000011920929, 0.5950000286102295, 0.675000011920929, 0.7250000238418579, 0.8050000071525574, 0.8149999976158142, 0.8349999785423279, 0.8600000143051147, 0.8650000095367432, 0.8799999952316284, 0.8949999809265137, 0.8949999809265137, 0.8899999856948853, 0.9049999713897705, 0.9049999713897705, 0.9100000262260437, 0.9150000214576721, 0.925000011920929, 0.925000011920929, 0.925000011920929, 0.9300000071525574, 0.925000011920929, 0.925000011920929, 0.9449999928474426, 0.9399999976158142, 0.9449999928474426, 0.9399999976158142, 0.949999988079071, 0.9399999976158142, 0.9449999928474426, 0.9449999928474426, 0.949999988079071, 0.9449999928474426, 0.9449999928474426, 0.949999988079071, 0.9549999833106995, 0.9449999928474426, 0.9449999928474426, 0.9449999928474426, 0.949999988079071, 0.9549999833106995, 0.9549999833106995, 0.949999988079071, 0.949999988079071, 0.949999988079071, 0.949999988079071, 0.949999988079071, 0.949999988079071, 0.949999988079071, 0.949999988079071, 0.9549999833106995, 0.949999988079071, 0.949999988079071, 0.949999988079071, 0.949999988079071, 0.949999988079071, 0.949999988079071, 0.949999988079071, 0.949999988079071, 0.9549999833106995, 0.9549999833106995, 0.9549999833106995, 0.9549999833106995, 0.9549999833106995, 0.9549999833106995, 0.9549999833106995, 0.9549999833106995, 0.949999988079071, 0.9549999833106995, 0.9549999833106995, 0.9549999833106995, 0.9549999833106995, 0.9549999833106995, 0.949999988079071, 0.949999988079071, 0.949999988079071, 0.949999988079071, 0.949999988079071, 0.949999988079071, 0.949999988079071, 0.949999988079071, 0.949999988079071, 0.949999988079071, 0.949999988079071, 0.949999988079071, 0.949999988079071, 0.949999988079071, 0.949999988079071, 0.949999988079071, 0.949999988079071, 0.949999988079071, 0.949999988079071, 0.949999988079071, 0.9449999928474426, 0.9449999928474426, 0.949999988079071, 0.949999988079071, 0.949999988079071, 0.949999988079071, 0.949999988079071]}\n"
     ]
    }
   ],
   "source": [
    "print( history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training accuracy</th>\n",
       "      <th>Validation accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7338</td>\n",
       "      <td>0.550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.7534</td>\n",
       "      <td>0.595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8044</td>\n",
       "      <td>0.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8407</td>\n",
       "      <td>0.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8747</td>\n",
       "      <td>0.805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Training accuracy  Validation accuracy\n",
       "0              0.7338                0.550\n",
       "1              0.7534                0.595\n",
       "2              0.8044                0.675\n",
       "3              0.8407                0.725\n",
       "4              0.8747                0.805\n",
       "..                ...                  ...\n",
       "95             1.0000                0.950\n",
       "96             1.0000                0.950\n",
       "97             1.0000                0.950\n",
       "98             1.0000                0.950\n",
       "99             1.0000                0.950\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"Training accuracy\": history.history['binary_accuracy'], \"Validation accuracy\": history.history['val_binary_accuracy']}).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot( history.history['val_binary_accuracy'], label='validation accuracy')\n",
    "plt.plot( history.history['binary_accuracy'], label = 'training accuracy')\n",
    "plt.ylim([0.8, 1.02])\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 100, 100, 3)]     0         \n",
      "                                                                 \n",
      " densenet169 (Functional)    (None, 1664)              12642880  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1664)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               166500    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,829,681\n",
      "Trainable params: 12,671,281\n",
      "Non-trainable params: 158,400\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-15 21:30:42.728312: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 360120000 exceeds 10% of free system memory.\n",
      "2022-08-15 21:30:43.156635: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 360120000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-15 21:30:55.903094: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.78GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-08-15 21:30:55.904378: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.78GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-08-15 21:30:55.921956: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.82GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-08-15 21:30:55.922015: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.82GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/94 [============================>.] - ETA: 0s - loss: 0.0051 - binary_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-15 21:31:16.377597: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.84GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-08-15 21:31:16.380906: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.84GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-08-15 21:31:18.618870: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.78GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-08-15 21:31:18.618913: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.78GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-08-15 21:31:18.634594: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.81GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2022-08-15 21:31:18.634632: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.81GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 40s 273ms/step - loss: 0.0050 - binary_accuracy: 1.0000 - val_loss: 0.2271 - val_binary_accuracy: 0.9500\n",
      "Epoch 2/5\n",
      "94/94 [==============================] - 18s 190ms/step - loss: 0.0018 - binary_accuracy: 1.0000 - val_loss: 0.2198 - val_binary_accuracy: 0.9550\n",
      "Epoch 3/5\n",
      "94/94 [==============================] - 18s 189ms/step - loss: 0.0011 - binary_accuracy: 1.0000 - val_loss: 0.2248 - val_binary_accuracy: 0.9550\n",
      "Epoch 4/5\n",
      "94/94 [==============================] - 18s 191ms/step - loss: 7.1046e-04 - binary_accuracy: 1.0000 - val_loss: 0.2254 - val_binary_accuracy: 0.9550\n",
      "Epoch 5/5\n",
      "94/94 [==============================] - 18s 195ms/step - loss: 5.0295e-04 - binary_accuracy: 1.0000 - val_loss: 0.2305 - val_binary_accuracy: 0.9550\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff720050bb0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unfreeze the base_model. Note that it keeps running in inference mode\n",
    "# since we passed `training=False` when calling it. This means that\n",
    "# the batchnorm layers will not update their batch statistics.\n",
    "# This prevents the batchnorm layers from undoing all the training\n",
    "# we've done so far.\n",
    "base_model.trainable = True\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-6),  # Low learning rate\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy()],\n",
    ")\n",
    "\n",
    "epochs = 5\n",
    "model.fit(x = x_train, y = y_train, epochs=epochs, validation_data = (x_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
