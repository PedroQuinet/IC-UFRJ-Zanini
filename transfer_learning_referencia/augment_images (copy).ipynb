{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZES = [100, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reads all images in filepath, resizes it according with 2D list img_sizes and \n",
    "# store them in a np_array. The string filepath can only contain images (no other\n",
    "# file types such as txt for example are allowed). \n",
    "# It works only for RGB images.\n",
    "def images_to_np_array(filepath, img_sizes):\n",
    "    #-----------------------------------------------------------------------------\n",
    "    # Args:\n",
    "    #     filepath:  String with the path to the directory containing the images.\n",
    "    #                It CANNOT end with the / character.\n",
    "    #     img_sizes: 2D array [num_rows, num_columns].\n",
    "    #-----------------------------------------------------------------------------\n",
    "\n",
    "    # list all files in filepath\n",
    "    list_of_files = [file for file in os.listdir(filepath)]\n",
    "\n",
    "    # number of image files\n",
    "    n_images = len(list_of_files)\n",
    "\n",
    "    # create np_array to store all images\n",
    "    array_images = np.zeros([n_images, IMAGE_SIZES[0], IMAGE_SIZES[1], 3])\n",
    "\n",
    "    for index in range( n_images ):\n",
    "\n",
    "        # get file name   \n",
    "        file_name = list_of_files[index]\n",
    "\n",
    "        # Open the image form working directory\n",
    "        image = Image.open(filepath + '/' + file_name)\n",
    "\n",
    "        # resize image\n",
    "        image_resized = image.resize(IMAGE_SIZES)\n",
    "\n",
    "        # convert it to numpy\n",
    "        np_image = np.asarray(image_resized)\n",
    "        array_images[index,:,:,:] = np_image\n",
    "\n",
    "    return array_images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all capivaras\n",
    "capivara_array = images_to_np_array(filepath = \"./capivara\", img_sizes = IMAGE_SIZES)\n",
    "y_capivara = np.zeros(capivara_array.shape[0])\n",
    "\n",
    "# read all dunkies\n",
    "burro_array = images_to_np_array(filepath = \"./burro\", img_sizes = IMAGE_SIZES)\n",
    "y_burro = np.ones(burro_array.shape[0])\n",
    "\n",
    "# create y vector with labels\n",
    "y = np.concatenate( (y_capivara, y_burro) )\n",
    "\n",
    "# concatenate and shuffle images\n",
    "array_images = np.concatenate( (capivara_array, burro_array), axis = 0 )\n",
    "number_of_images = array_images.shape[0]\n",
    "permuted_index = np.random.permutation(number_of_images)\n",
    "array_images = array_images[permuted_index, :, :, :]\n",
    "y = y[permuted_index]\n",
    "\n",
    "# splitting training and test sets\n",
    "\n",
    "x_train = array_images[0:700,:,:,:]\n",
    "y_train = y[0:700]\n",
    "\n",
    "x_test = array_images[700:,:,:,:]\n",
    "y_test = y[700:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing \n",
    "array_images = tf.keras.applications.densenet.preprocess_input(array_images, data_format = \"channels_last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-14 21:04:44.150034: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-14 21:04:44.193016: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-14 21:04:44.193282: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-14 21:04:44.193960: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-14 21:04:44.194738: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-14 21:04:44.194913: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-14 21:04:44.195057: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-14 21:04:45.072610: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-14 21:04:45.072798: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-14 21:04:45.073016: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-14 21:04:45.073799: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2633 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# initialize model with weights treined in imagenet \n",
    "base_model = tf.keras.applications.DenseNet169(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(IMAGE_SIZES[0], IMAGE_SIZES[1], 3),\n",
    "    pooling=\"avg\",\n",
    "    classes=2,\n",
    "    classifier_activation=\"None\"\n",
    ")\n",
    "\n",
    "# Freeze model weights\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential(\n",
    "    [tf.keras.layers.RandomFlip(\"horizontal\"), tf.keras.layers.RandomRotation(0.5),]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 100, 100, 3)]     0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 100, 100, 3)       0         \n",
      "                                                                 \n",
      " densenet169 (Functional)    (None, 1664)              12642880  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1664)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               166500    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,829,681\n",
      "Trainable params: 186,801\n",
      "Non-trainable params: 12,642,880\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(IMAGE_SIZES[0], IMAGE_SIZES[1], 3))\n",
    "# apply data augmentation\n",
    "x = data_augmentation(inputs)\n",
    "# We make sure that the base_model is running in inference mode here,\n",
    "# by passing `training=False`. This is important for fine-tuning, as you will\n",
    "# learn in a few paragraphs.\n",
    "x = base_model(x, training=False)\n",
    "# Convert features of shape `base_model.output_shape[1:]` to vectors\n",
    "x = tf.keras.layers.Flatten(data_format = \"channels_last\")(x)\n",
    "x = tf.keras.layers.Dense(100, activation = \"relu\")(x)\n",
    "x = tf.keras.layers.Dense(100, activation = \"relu\")(x)\n",
    "x = tf.keras.layers.Dense(100, activation = \"relu\")(x)\n",
    "outputs = tf.keras.layers.Dense(1)(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkpoint_filepath = \"./trained_model_checkpoint\"\n",
    "\n",
    "# define the callback (to save the weights that gave best val_accuracy during training)\n",
    "#callback = tf.keras.callbacks.ModelCheckpoint(monitor='val_accuracy',\n",
    "#                                              mode = \"max\",\n",
    "#                                              save_best_only = True,\n",
    "#                                              filepath = checkpoint_filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.0151 - binary_accuracy: 0.9943 - accuracy: 0.9943"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate = 0.0001),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy()],\n",
    ")\n",
    "\n",
    "history = model.fit(x = x_train, \n",
    "                    y = y_train, \n",
    "                    epochs = 10, \n",
    "                    validation_data = (x_test, y_test), \n",
    "                    batch_size = 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 - 0s - loss: 0.1863 - binary_accuracy: 0.9559 - 394ms/epoch - 56ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1863396018743515, 0.9558823704719543]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(y = y_test, x = x_test, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 2s 56ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>probability</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.999971e-01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.236003e-04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.428722e-12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.243708e-08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.920243e-11</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>9.999963e-01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>3.788940e-07</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>8.804154e-02</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>3.877875e-06</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      probability  label\n",
       "0    9.999971e-01    1.0\n",
       "1    1.236003e-04    0.0\n",
       "2    1.428722e-12    0.0\n",
       "3    2.243708e-08    0.0\n",
       "4    5.920243e-11    0.0\n",
       "..            ...    ...\n",
       "199  9.999963e-01    1.0\n",
       "200  3.788940e-07    0.0\n",
       "201  8.804154e-02    1.0\n",
       "202  1.000000e+00    1.0\n",
       "203  3.877875e-06    0.0\n",
       "\n",
       "[204 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(x_test)\n",
    "pd.DataFrame( {\"probability\": tf.keras.activations.sigmoid(predictions)[:,0], \"label\": y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze the base_model. Note that it keeps running in inference mode\n",
    "# since we passed `training=False` when calling it. This means that\n",
    "# the batchnorm layers will not update their batch statistics.\n",
    "# This prevents the batchnorm layers from undoing all the training\n",
    "# we've done so far.\n",
    "base_model.trainable = True\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-5),  # Low learning rate\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy()],\n",
    ")\n",
    "\n",
    "epochs = 10\n",
    "model.fit(x = x_train, y = y_train, epochs=epochs, validation_data = (x_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
